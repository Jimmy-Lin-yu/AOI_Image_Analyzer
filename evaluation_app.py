# evaluation_app.py
import gradio as gr
import cv2
import pandas as pd
import os
import datetime
import shutil
from pathlib import Path
from image_evaluation import ImageQualityAnalyzer
# from yolo_model import YOLOImageProcessor #æš«æ™‚åœæ­¢ä½¿ç”¨YOLO
from image_zip_manage import ImageZipManager
from u2net_cropper import U2NetCropper
from datetime import datetime
# ------------------ åˆ†æåœ–ç‰‡ ------------------
import os
import cv2
import pandas as pd
import numpy as np
from datetime import datetime


# ------------------ (1) ä¸Šå‚³æª”æ¡ˆå„²å­˜ ------------------
def store_uploaded_files(uploaded, upload_folder):
    """
    æ ¹æ“šä¸Šå‚³å…§å®¹ï¼ˆå–®å¼µåœ–ç‰‡ã€ZIP æˆ–å–®å€‹æª”æ¡ˆï¼‰ï¼Œ
    å°‡å½±åƒå­˜åˆ° upload_folderï¼Œä¸¦å›å‚³è™•ç†çµæœè¨Šæ¯ã€‚
    ZIP åˆ†æ”¯å…ˆå‘¼å« ImageZipManager.decompress_only() åªåšè§£å£“ï¼Œ
    å†åœ¨é€™è£¡å°æ¯å€‹æª”æ¡ˆå‘¼å« mgr.translate() ä¸¦ä¸€æ¬¡è™•ç†ç¿»è­¯æª”åã€‚
    """
    mgr = ImageZipManager()
    result = ""
    os.makedirs(upload_folder, exist_ok=True)

    # 1a. è™•ç†å–®å¼µ np.ndarray
    if isinstance(uploaded, np.ndarray):
        image_name = f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
        image_bgr  = cv2.cvtColor(uploaded, cv2.COLOR_RGB2BGR)
        save_path  = os.path.join(upload_folder, image_name)
        cv2.imwrite(save_path, image_bgr)
        result += f"å·²å„²å­˜å–®å¼µåœ–ç‰‡ï¼š{image_name}\n"

    # 1b. è™•ç† ZIP
    elif hasattr(uploaded, "name") and uploaded.name.lower().endswith(".zip"):
        result += "ğŸ“¦ ZIP è§£å£“ä¸¦ç¿»è­¯ä¸­...\n"
        try:
            # å…ˆåªè§£å£“ï¼Œä¸ç¿»è­¯
            extracted = mgr.decompress_images(uploaded.name, upload_folder)
            for src in extracted:
                base = os.path.basename(src)
                # å…ˆç•¥é bad_keyword
                if mgr.bad_kw in base:
                    os.remove(src)
                    result += f"{base} â†’ å«é—œéµå­—å·²åˆªé™¤\n"
                    continue
                # translate & rename
                new_base = mgr.translate(base)
                dst = os.path.join(upload_folder, new_base)
                os.rename(src, dst)
                result += f"ç¿»è­¯æª”åï¼š{base} â†’ {new_base}\n"
        except Exception as e:
            result += f"âŒ ZIP è™•ç†å¤±æ•—ï¼š{e}\n"

    # 1c. è™•ç†å–®æª”å½±åƒ
    elif hasattr(uploaded, "name") and \
         uploaded.name.lower().endswith((".png",".jpg",".jpeg",".bmp",".tiff")):
        base = os.path.basename(uploaded.name)
        if mgr.bad_kw in base:
            result += f"{base} â†’ å«é—œéµå­—å·²ç•¥é\n"
        else:
            new_base = mgr.translate(base)
            dst = os.path.join(upload_folder, new_base)
            try:
                shutil.copy(uploaded.name, dst)
                result += f"å·²å„²å­˜ï¼š{new_base}\n"
            except Exception as e:
                result += f"âŒ è¤‡è£½å¤±æ•—ï¼š{e}\n"

    else:
        return "âŒ è«‹ä¸Šå‚³åœ–ç‰‡ã€ZIP æˆ–æœ‰æ•ˆçš„å½±åƒæª”"

    return result


# ------------------ (2) YOLO æ¨¡å‹è™•ç† ------------------ #æš«æ™‚åœæ­¢ä½¿ç”¨YOLO
# def process_uploaded_images_with_yolo(upload_folder, crop_folder, yolo_model_path):
#     """
#     å‘¼å« YOLO æ¨¡å‹è™•ç† upload_folder ä¸­çš„æ‰€æœ‰åœ–ç‰‡ï¼Œ
#     å°‡è£åˆ‡å¾Œçš„åœ–ç‰‡å­˜å…¥ crop_folderï¼Œ
#     æª”åæ ¼å¼è‹¥æœªç¬¦åˆã€ŒåŸæª”å_crop.jpgã€å‰‡èª¿æ•´ã€‚
#     """
#     os.makedirs(crop_folder, exist_ok=True)
    
#     yolo_processor = YOLOImageProcessor(upload_folder, crop_folder)
#     yolo_processor.process_images()
#     result = f"âœ… YOLO è™•ç†å®Œæˆï¼Œå·²å°‡è£åˆ‡å¾Œåœ–ç‰‡å­˜å…¥ {crop_folder}\n"
#     return result


def process_uploaded_images_with_u2net(upload_folder, crop_folder, model_path):
    os.makedirs(crop_folder, exist_ok=True)
    cropper = U2NetCropper(model_path=model_path)
    saved = cropper.crop_images(str(upload_folder), str(crop_folder))
    return f"âœ… UÂ²-Net åˆ‡å‰²å®Œæˆï¼Œå…± {len(saved)} å¼µåœ–å­˜å…¥ {crop_folder}"

# ------------------ (3) è£åˆ‡å¾Œåœ–åƒå“è³ªåˆ†æèˆ‡ CSV æ›´æ–° ------------------
def quality_analysis_on_cropped(crop_folder: Path, csv_path: Path) -> str:
    """
    é‡å° crop_folder ä¸­çš„è£åˆ‡å¾Œåœ–ç‰‡é€²è¡Œå½±åƒå“è³ªåˆ†æï¼Œ
    è‹¥æª”åä¸ç¬¦åˆ 'filename_crop.jpg' æ ¼å¼å‰‡é‡æ–°å‘½åï¼Œ
    ä¸¦å°‡åˆ†æçµæœè¨˜éŒ„åˆ° CSV (csv_path)ã€‚
    """
    analyzer = ImageQualityAnalyzer(str(crop_folder))
    records = []
    result = ""
    

    # ---- å…ˆæº–å‚™èˆŠçš„ DataFrameï¼Œé¿å… KeyError ----
    if csv_path.exists() and csv_path.stat().st_size > 0:
        df_old = pd.read_csv(csv_path)
        if "uploaded_image" not in df_old.columns:
            # å¦‚æœç¼ºæ¬„ï¼Œå°±æ¸…æ‰é‡æ–°é–‹å§‹
            df_old = pd.DataFrame(columns=["uploaded_image", "output"])
    else:
        # CSV ä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œå°±å»ºç«‹ç©ºè¡¨
        df_old = pd.DataFrame(columns=["uploaded_image", "output"])


    for file in os.listdir(crop_folder):
        if file.lower().endswith((".png", ".jpg", ".jpeg"," .bmp", ".tiff")):
            base, ext = os.path.splitext(file)
            # æª¢æŸ¥æª”åæ˜¯å¦åŒ…å« _cropï¼Œè‹¥ç„¡å‰‡é‡æ–°å‘½å
            if not base.endswith("_crop"):
                new_name = f"{base}_crop.jpg"
                old_path = os.path.join(crop_folder, file)
                new_path = os.path.join(crop_folder, new_name)
                os.rename(old_path, new_path)
            else:
                new_name = file
                new_path = os.path.join(crop_folder, new_name)
            
            image = cv2.imread(new_path)
            if image is None:
                result += f"{new_name} â†’ âš ï¸ ç„¡æ³•è®€å–é€²è¡Œå“è³ªåˆ†æ\n"
                continue
            
            metrics = {
                "sharpness": analyzer.calculate_sharpness(image),
                "exposure": analyzer.calculate_exposure(image),
                "contrast": analyzer.calculate_contrast(image),
                "uniformity": analyzer.calculate_light_uniformity(image),
                # "defect": analyzer.calculate_defect_score(image)
            }
            scores, total = analyzer.evaluate_quality(metrics)
            output_text = "å½±åƒå“è³ªåˆ†æçµæœï¼š\n"
            for (k, v), score in zip(metrics.items(), scores):
                output_text += f"  {k.capitalize()}: {v:.2f} â†’ Score {score}\n"
            output_text += f"\nTotal Quality: {total:.1f}%"
            
            records.append({
                "uploaded_image": new_path,
                "output": output_text
            })
            result += f"{new_name} â†’ åˆ†æå®Œæˆ\n"
    
    # å°‡åˆ†æçµæœå¯«å…¥ CSVï¼Œè‹¥ CSV å­˜åœ¨å‰‡é¿å…é‡è¤‡è¨˜éŒ„
    os.makedirs(os.path.dirname(csv_path), exist_ok=True)
    if os.path.exists(csv_path) and os.path.getsize(csv_path) > 0:
        df_old = pd.read_csv(csv_path)
        existing = set(df_old["uploaded_image"].apply(os.path.basename).tolist())
        df_new = pd.DataFrame(records)
        df_new = df_new[~df_new["uploaded_image"].apply(os.path.basename).isin(existing)]
        df_all = pd.concat([df_old, df_new], ignore_index=True)
    else:
        df_all = pd.DataFrame(records)
    df_all.to_csv(csv_path, index=False)
    result += f"âœ… å“è³ªåˆ†æå®Œæˆï¼Œå…± {len(records)} ç­†è³‡æ–™è¨˜éŒ„åˆ° CSV\n"
    return result


# ------------------ é¡¯ç¤ºå‰äº”å ------------------
def show_flagged_data():
    try:
        csv_path = os.path.join(".gradio", "flagged", "dataset1.csv")
        if not os.path.exists(csv_path):
            return pd.DataFrame(columns=["Image","Total Quality","Sharpness", "Exposure", "Contrast", "Uniformity", "Timestamp"])

        df = pd.read_csv(csv_path)

        # 1. Fill empty output cells with empty string, then convert everything to string.
        df["output"] = df["output"].fillna("").astype(str)

        # ç”¨æ­£å‰‡è¡¨é”å¼è§£ææ•¸å€¼
        import re

        def extract_metric(text, metric_name):
            pattern = rf"{metric_name}:\s*([0-9.]+)"
            match = re.search(pattern, text)
            return float(match.group(1)) if match else None

        def extract_quality(text):
            match = re.search(r"Total Quality: ([0-9.]+)%", text)
            return float(match.group(1)) if match else None

        df["Total Quality"] = df["output"].apply(extract_quality)
        df["Sharpness"] = df["output"].apply(lambda x: extract_metric(x, "Sharpness"))
        df["Exposure"] = df["output"].apply(lambda x: extract_metric(x, "Exposure"))
        df["Contrast"] = df["output"].apply(lambda x: extract_metric(x, "Contrast"))
        df["Uniformity"] = df["output"].apply(lambda x: extract_metric(x, "Uniformity"))
        # df["Defect"] = df["output"].apply(lambda x: extract_metric(x, "Defect"))

        df["Image"] = df["uploaded_image"].apply(os.path.basename)
        df["Timestamp"] = pd.to_datetime(df["uploaded_image"].apply(lambda f: datetime.fromtimestamp(os.path.getctime(f)) if os.path.exists(f) else pd.NaT))

        top5 = df.sort_values(by="Total Quality", ascending=False).head(5)
        print("âš ï¸ è®€å–æˆåŠŸï¼š", top5)
        return top5[["Image", "Sharpness", "Exposure", "Contrast", "Uniformity", "Total Quality", "Timestamp"]]

    except Exception as e:
        return pd.DataFrame({"éŒ¯èª¤": [f"âš ï¸ è®€å–å¤±æ•—ï¼š{e}"]})

# ------------------ é è¦½é¸å®šåœ–ç‰‡ ------------------
def display_selected_image(image_name):
    try:
        csv_path = os.path.join(".gradio", "flagged", "dataset1.csv")
        if not os.path.exists(csv_path):
            return None

        df = pd.read_csv(csv_path)

        # ç”Ÿæˆ Image æ¬„ä½ï¼ˆé¿å… NaNï¼‰
        df["Image"] = df["uploaded_image"].apply(lambda x: os.path.basename(str(x)) if pd.notnull(x) else "")

        match = df[df["Image"] == image_name]

        if not match.empty:
            image_path = match.iloc[0]["uploaded_image"]
            if isinstance(image_path, str) and os.path.exists(image_path):
                return image_path
        return None

    except Exception as e:
        print("âš ï¸ é è¦½éŒ¯èª¤ï¼š", e)
        return None



# ------------------ å‚™ä»½èˆ‡åˆªé™¤ CSV æª”æ¡ˆ ------------------
def backup_csv():
    src = os.path.join(".gradio", "flagged", "dataset1.csv")
    dst = os.path.join("flagged", "backup_dataset.csv")
    if os.path.exists(src):
        os.makedirs("flagged", exist_ok=True)
        shutil.copy(src, dst)
        return f"âœ… å‚™ä»½æˆåŠŸï¼Œå„²å­˜ç‚ºï¼š{dst}"
    else:
        return "âš ï¸ æ‰¾ä¸åˆ° dataset1.csv"


def clear_images_csv():
    """
    1. æ¸…ç©º .gradio/flagged/dataset1.csv
    2. åˆªé™¤ .gradio/flagged/uploaded_image/ å…§æ‰€æœ‰æª”æ¡ˆ
    3. åˆªé™¤ .gradio/flagged/crop_image/ å…§æ‰€æœ‰æª”æ¡ˆ
    """
    base_dir   = ".gradio/flagged"
    csv_path   = os.path.join(base_dir, "dataset1.csv")
    upload_dir  = os.path.join(base_dir, "uploaded_image")
    crop_dir = os.path.join(base_dir, "crop_image")

    try:
        # --- 1ï¸âƒ£ é‡è¨­ CSV ---
        if os.path.exists(csv_path):
            pd.DataFrame(columns=["uploaded_image", "output"]).to_csv(csv_path, index=False)
        else:
            # å¦‚æœæª”æ¡ˆä¸å­˜åœ¨ä¹Ÿç„¡å¦¨ï¼Œç›´æ¥ç•¶ä½œå·²æ¸…ç©º
            pass

        # --- 2ï¸âƒ£ åˆªé™¤ uploaded_image å…§æ‰€æœ‰æª”æ¡ˆ ---
        if os.path.isdir(upload_dir):
            for root, _, files in os.walk(upload_dir):
                for f in files:
                    try:
                        os.remove(os.path.join(root, f))
                    except Exception as e:
                        print("âš ï¸ ç„¡æ³•åˆªé™¤", f, "ï¼š", e)

        # --- 3ï¸âƒ£ åˆªé™¤ crop_image å…§æ‰€æœ‰æª”æ¡ˆ ---
        if os.path.isdir(crop_dir):
            for root, _, files in os.walk(crop_dir):
                for f in files:
                    try:
                        os.remove(os.path.join(root, f))
                    except Exception as e:
                        print("âš ï¸ ç„¡æ³•åˆªé™¤", f, "ï¼š", e)

        return "âœ… æ¸…é™¤æˆåŠŸï¼šCSV å·²é‡è¨­ï¼Œuploaded_image èˆ‡ crop_image å…§æª”æ¡ˆå·²åˆªé™¤"
    except Exception as e:
        return f"âŒ æ¸…é™¤å¤±æ•—ï¼š{e}"

# ------------------ æ¯å€‹æŒ‰éˆ•ç¶å®šä¸€å€‹å‰äº”ååœ–ç‰‡åç¨± ------------------
def get_top_image(index):
    try:
        csv_path = os.path.join(".gradio", "flagged", "dataset1.csv")
        df = pd.read_csv(csv_path)
        df["Image"] = df["uploaded_image"].apply(lambda x: os.path.basename(str(x)) if pd.notnull(x) else "")
        df["Total Quality"] = df["output"].str.extract(r"Total Quality: ([0-9.]+)%").astype(float)
        top5 = df.sort_values(by="Total Quality", ascending=False).head(5)
        return top5.iloc[index]["Image"] if index < len(top5) else None
    except:
        return None




# ------------------ ä¸»æµç¨‹ï¼šåˆ†æä¸Šå‚³è³‡æ–™ ------------------

#é é¢1:æˆåƒå“è³ªè©•åˆ†
def analyze_input(uploaded):
    """
    Gradioã€ˆæˆåƒå“è³ªè©•åˆ†ã€‰é é¢çš„ä¸»æµç¨‹ï¼š
      1. å„²å­˜ä¸Šå‚³æª” (ZIP / å–®åœ–) è‡³ .gradio/flagged/uploaded_image
      2. ä»¥ YOLO ç”¢ç”Ÿè£åˆ‡åœ– â†’ .gradio/flagged/crop_image
      3. å°è£åˆ‡åœ–åšå“è³ªè©•åˆ†ä¸¦å¯«å…¥ dataset1.csv
    """
    base_dir        = Path(".gradio/flagged")
    upload_dir      = base_dir / "uploaded_image"
    crop_dir        = base_dir / "crop_image"
    csv_path        = base_dir / "dataset1.csv"
    messages: list[str] = []                      # æ”¶é›†å„æ­¥é©Ÿå›å‚³æ–‡å­—

    def _append(text):                            # å°å·¥å…·ï¼šé¿å…é‡è¤‡å¯« "+="
        if text:
            messages.append(text.strip())

    # â”€â”€ STEP-1 å„²å­˜æª”æ¡ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        _append(store_uploaded_files(uploaded, upload_dir))
    except Exception as e:
        _append(f"âŒ å„²å­˜æª”æ¡ˆå¤±æ•—ï¼š{e}")

    # â”€â”€ STEP-2 YOLO è£åˆ‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # try:
    #     _append(process_uploaded_images_with_yolo(upload_dir, crop_dir, YOLO_MODEL_PATH))
    # except Exception as e:
    #     _append(f"âŒ YOLO è™•ç†å¤±æ•—ï¼š{e}")

    try:
         _append(process_uploaded_images_with_u2net(upload_dir, crop_dir, U2net_MODEL_PATH))
    except Exception as e:
         _append(f"âŒ YOLO è™•ç†å¤±æ•—ï¼š{e}")

    # â”€â”€ STEP-3 å“è³ªè©•åˆ† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        _append(quality_analysis_on_cropped(crop_dir, csv_path))
    except Exception as e:
        _append(f"âŒ å“è³ªè©•åˆ†å¤±æ•—ï¼š{e}")

    # æœ€çµ‚å›å‚³
    return "\n".join(messages) if messages else "âš ï¸ ç„¡ä»»ä½•çµæœ"


# ------------------ Gradio UI ------------------
with gr.Blocks(title="æˆåƒå“è³ªè©•åˆ†ç³»çµ±") as demo:
    demo.flagging_dir = ".gradio/flagged"
    demo.allow_flagging = "manual"

    gr.Markdown("## ğŸ“¸ Image Quality Analyzer")
    with gr.TabItem("æˆåƒå“è³ªè©•åˆ†"):
        with gr.Row():
            with gr.Column():
                image_input = gr.File(file_types=["image", ".zip"], label="ä¸Šå‚³åœ–ç‰‡æˆ– ZIP å£“ç¸®è³‡æ–™å¤¾")
                submit_btn = gr.Button("åˆ†æåœ–ç‰‡")
                output_text = gr.Textbox(label="åˆ†æçµæœ", lines=8)
            with gr.Column():
                history_btn = gr.Button("ğŸ“Š é¡¯ç¤ºå“è³ªæœ€ä½³å‰äº”å")
                df_output = gr.Dataframe(
                    interactive=True,
                    headers=["Image", "Sharpness", "Exposure", "Contrast", "Uniformity", "Total Quality", "Timestamp"],
                )
                selected_image = gr.Image(label="ğŸ” é è¦½åœ–ç‰‡")  # é è¦½åœ–
                preview_buttons = [gr.Button(f"æŸ¥çœ‹ç¬¬{i+1}ååœ–ç‰‡") for i in range(5)]  # ğŸ”˜ äº”å€‹æŒ‰éˆ•
                backup_btn = gr.Button("ğŸ“ å‚™ä»½ CSV")
                backup_result = gr.Textbox(label="å‚™ä»½çµæœ")
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤ dataset1.csv")
                clear_result = gr.Textbox(label="æ¸…é™¤çµæœ")

        submit_btn.click(analyze_input, inputs=image_input, outputs=output_text)
        history_btn.click(show_flagged_data, outputs=df_output)

        for i, btn in enumerate(preview_buttons):
            btn.click(
                lambda idx=i: display_selected_image(get_top_image(idx)),
                outputs=selected_image
            )

        backup_btn.click(backup_csv, outputs=backup_result)
        clear_btn.click(clear_images_csv, outputs=clear_result)

        
if __name__ == "__main__":
    # YOLO_MODEL_PATH = "/app/best.pt" 
    U2net_MODEL_PATH = "/app/u2net.pth"
    demo.launch(server_name="0.0.0.0", server_port=7860)
